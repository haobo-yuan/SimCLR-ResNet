{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sthalles/SimCLR/blob/simclr-refactor/feature_eval/mini_batch_logistic_regression_evaluator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YUemQib7ZE4D"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDfbL3w_Z0Od",
        "outputId": "e1aac3a0-3af4-42a5-f583-1ab3f55690d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BfIPl0G6_RrT"
      },
      "outputs": [],
      "source": [
        "def get_stl10_data_loaders(download, shuffle=False, batch_size=256):\n",
        "  train_dataset = datasets.STL10('./data', split='train', download=download,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                            num_workers=0, drop_last=False, shuffle=shuffle)\n",
        "\n",
        "  test_dataset = datasets.STL10('./data', split='test', download=download,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "  test_loader = DataLoader(test_dataset, batch_size=2*batch_size,\n",
        "                            num_workers=10, drop_last=False, shuffle=shuffle)\n",
        "  return train_loader, test_loader\n",
        "\n",
        "def get_cifar10_data_loaders(download, shuffle=False, batch_size=256):\n",
        "  train_dataset = datasets.CIFAR10('./data', train=True, download=download,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                            num_workers=0, drop_last=False, shuffle=shuffle)\n",
        "\n",
        "  test_dataset = datasets.CIFAR10('./data', train=False, download=download,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "  test_loader = DataLoader(test_dataset, batch_size=2*batch_size,\n",
        "                            num_workers=10, drop_last=False, shuffle=shuffle)\n",
        "  return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WK6jAeMsRVQp"
      },
      "outputs": [],
      "source": [
        "def modify_resnet18_for_cifar10(model):\n",
        "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    model.maxpool = nn.Identity()\n",
        "\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "edr6RhP2PdVq"
      },
      "outputs": [],
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "4AIfgq41GuTT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b493d18-60cd-4286-f6e0-e65ec00819ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "########################checkpoint checkpoint_0000.pth.tar##########################\n",
            "\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 0\tTop1 Train accuracy 32.97552490234375\tTop1 Test accuracy: 37.60397720336914\tTop5 test acc: 87.5608901977539\n",
            "Epoch 1\tTop1 Train accuracy 38.27248001098633\tTop1 Test accuracy: 39.330196380615234\tTop5 test acc: 88.32548522949219\n",
            "Epoch 2\tTop1 Train accuracy 39.52367401123047\tTop1 Test accuracy: 40.341224670410156\tTop5 test acc: 88.73448944091797\n",
            "Epoch 3\tTop1 Train accuracy 40.45280456542969\tTop1 Test accuracy: 40.79159164428711\tTop5 test acc: 89.03722381591797\n",
            "Epoch 4\tTop1 Train accuracy 41.1224479675293\tTop1 Test accuracy: 41.298255920410156\tTop5 test acc: 89.42670440673828\n",
            "Epoch 5\tTop1 Train accuracy 41.660552978515625\tTop1 Test accuracy: 41.794002532958984\tTop5 test acc: 89.72081756591797\n",
            "Epoch 6\tTop1 Train accuracy 42.226959228515625\tTop1 Test accuracy: 42.15303421020508\tTop5 test acc: 90.02240753173828\n",
            "Epoch 7\tTop1 Train accuracy 42.61559295654297\tTop1 Test accuracy: 42.55112838745117\tTop5 test acc: 90.19071960449219\n",
            "Epoch 8\tTop1 Train accuracy 43.06241989135742\tTop1 Test accuracy: 43.04802322387695\tTop5 test acc: 90.31652069091797\n",
            "Epoch 9\tTop1 Train accuracy 43.39126205444336\tTop1 Test accuracy: 43.23127365112305\tTop5 test acc: 90.45209503173828\n",
            "Epoch 10\tTop1 Train accuracy 43.677852630615234\tTop1 Test accuracy: 43.64142990112305\tTop5 test acc: 90.57904815673828\n",
            "Epoch 11\tTop1 Train accuracy 43.8911018371582\tTop1 Test accuracy: 43.896484375\tTop5 test acc: 90.57904815673828\n",
            "Epoch 12\tTop1 Train accuracy 44.096378326416016\tTop1 Test accuracy: 44.16015625\tTop5 test acc: 90.65717315673828\n",
            "Epoch 13\tTop1 Train accuracy 44.29966354370117\tTop1 Test accuracy: 44.42267990112305\tTop5 test acc: 90.72553253173828\n",
            "Epoch 14\tTop1 Train accuracy 44.558753967285156\tTop1 Test accuracy: 44.704734802246094\tTop5 test acc: 90.78412628173828\n",
            "Epoch 15\tTop1 Train accuracy 44.73772048950195\tTop1 Test accuracy: 44.85007095336914\tTop5 test acc: 90.87201690673828\n",
            "Epoch 16\tTop1 Train accuracy 44.961334228515625\tTop1 Test accuracy: 45.04538345336914\tTop5 test acc: 90.90131378173828\n",
            "Epoch 17\tTop1 Train accuracy 45.1068229675293\tTop1 Test accuracy: 45.20048141479492\tTop5 test acc: 90.93061065673828\n",
            "Epoch 18\tTop1 Train accuracy 45.27463150024414\tTop1 Test accuracy: 45.40555953979492\tTop5 test acc: 90.97943878173828\n",
            "Epoch 19\tTop1 Train accuracy 45.450016021728516\tTop1 Test accuracy: 45.629024505615234\tTop5 test acc: 91.00873565673828\n",
            "Epoch 20\tTop1 Train accuracy 45.579559326171875\tTop1 Test accuracy: 45.793888092041016\tTop5 test acc: 91.13338470458984\n",
            "Epoch 21\tTop1 Train accuracy 45.710697174072266\tTop1 Test accuracy: 45.892696380615234\tTop5 test acc: 91.12361907958984\n",
            "Epoch 22\tTop1 Train accuracy 45.8246955871582\tTop1 Test accuracy: 46.029415130615234\tTop5 test acc: 91.24080657958984\n",
            "Epoch 23\tTop1 Train accuracy 45.97616195678711\tTop1 Test accuracy: 46.068477630615234\tTop5 test acc: 91.31893157958984\n",
            "Epoch 24\tTop1 Train accuracy 46.06983184814453\tTop1 Test accuracy: 46.195430755615234\tTop5 test acc: 91.33846282958984\n",
            "Epoch 25\tTop1 Train accuracy 46.1957893371582\tTop1 Test accuracy: 46.322383880615234\tTop5 test acc: 91.34822845458984\n",
            "Epoch 26\tTop1 Train accuracy 46.209739685058594\tTop1 Test accuracy: 46.312618255615234\tTop5 test acc: 91.40567779541016\n",
            "Epoch 27\tTop1 Train accuracy 46.313377380371094\tTop1 Test accuracy: 46.351680755615234\tTop5 test acc: 91.46427154541016\n",
            "Epoch 28\tTop1 Train accuracy 46.419002532958984\tTop1 Test accuracy: 46.351680755615234\tTop5 test acc: 91.50218963623047\n",
            "Epoch 29\tTop1 Train accuracy 46.51068115234375\tTop1 Test accuracy: 46.43095016479492\tTop5 test acc: 91.57054901123047\n",
            "Epoch 30\tTop1 Train accuracy 46.58481979370117\tTop1 Test accuracy: 46.47977828979492\tTop5 test acc: 91.58031463623047\n",
            "Epoch 31\tTop1 Train accuracy 46.66254806518555\tTop1 Test accuracy: 46.516544342041016\tTop5 test acc: 91.64867401123047\n",
            "Epoch 32\tTop1 Train accuracy 46.76618194580078\tTop1 Test accuracy: 46.615352630615234\tTop5 test acc: 91.67797088623047\n",
            "Epoch 33\tTop1 Train accuracy 46.85825729370117\tTop1 Test accuracy: 46.760684967041016\tTop5 test acc: 91.72563934326172\n",
            "Epoch 34\tTop1 Train accuracy 46.96149444580078\tTop1 Test accuracy: 46.848575592041016\tTop5 test acc: 91.76470184326172\n",
            "Epoch 35\tTop1 Train accuracy 47.07708740234375\tTop1 Test accuracy: 46.916934967041016\tTop5 test acc: 91.83191680908203\n",
            "Epoch 36\tTop1 Train accuracy 47.14285659790039\tTop1 Test accuracy: 46.946231842041016\tTop5 test acc: 91.90027618408203\n",
            "Epoch 37\tTop1 Train accuracy 47.21022033691406\tTop1 Test accuracy: 46.975528717041016\tTop5 test acc: 91.94795989990234\n",
            "Epoch 38\tTop1 Train accuracy 47.31584548950195\tTop1 Test accuracy: 46.98414611816406\tTop5 test acc: 91.97725677490234\n",
            "Epoch 39\tTop1 Train accuracy 47.40553283691406\tTop1 Test accuracy: 47.01344299316406\tTop5 test acc: 92.04446411132812\n",
            "Epoch 40\tTop1 Train accuracy 47.4653205871582\tTop1 Test accuracy: 47.05250549316406\tTop5 test acc: 92.08352661132812\n",
            "Epoch 41\tTop1 Train accuracy 47.55699920654297\tTop1 Test accuracy: 47.20760726928711\tTop5 test acc: 92.10305786132812\n",
            "Epoch 42\tTop1 Train accuracy 47.61878204345703\tTop1 Test accuracy: 47.20760726928711\tTop5 test acc: 92.09329223632812\n",
            "Epoch 43\tTop1 Train accuracy 47.70647048950195\tTop1 Test accuracy: 47.25643539428711\tTop5 test acc: 92.10305786132812\n",
            "Epoch 44\tTop1 Train accuracy 47.77024841308594\tTop1 Test accuracy: 47.35179138183594\tTop5 test acc: 92.08352661132812\n",
            "Epoch 45\tTop1 Train accuracy 47.81808090209961\tTop1 Test accuracy: 47.43968200683594\tTop5 test acc: 92.08352661132812\n",
            "Epoch 46\tTop1 Train accuracy 47.850364685058594\tTop1 Test accuracy: 47.538490295410156\tTop5 test acc: 92.1116714477539\n",
            "Epoch 47\tTop1 Train accuracy 47.93805694580078\tTop1 Test accuracy: 47.538490295410156\tTop5 test acc: 92.14958953857422\n",
            "Epoch 48\tTop1 Train accuracy 48.00581741333008\tTop1 Test accuracy: 47.577552795410156\tTop5 test acc: 92.17888641357422\n",
            "Epoch 49\tTop1 Train accuracy 48.03969955444336\tTop1 Test accuracy: 47.63499450683594\tTop5 test acc: 92.18865203857422\n",
            "Epoch 50\tTop1 Train accuracy 48.079559326171875\tTop1 Test accuracy: 47.67405700683594\tTop5 test acc: 92.1875\n",
            "Epoch 51\tTop1 Train accuracy 48.1293830871582\tTop1 Test accuracy: 47.75965118408203\tTop5 test acc: 92.22541809082031\n",
            "Epoch 52\tTop1 Train accuracy 48.191165924072266\tTop1 Test accuracy: 47.80847930908203\tTop5 test acc: 92.23518371582031\n",
            "Epoch 53\tTop1 Train accuracy 48.229034423828125\tTop1 Test accuracy: 47.84754180908203\tTop5 test acc: 92.27424621582031\n",
            "Epoch 54\tTop1 Train accuracy 48.27287673950195\tTop1 Test accuracy: 47.86707305908203\tTop5 test acc: 92.26448059082031\n",
            "Epoch 55\tTop1 Train accuracy 48.31313705444336\tTop1 Test accuracy: 47.91475296020508\tTop5 test acc: 92.24494934082031\n",
            "Epoch 56\tTop1 Train accuracy 48.335060119628906\tTop1 Test accuracy: 47.98311233520508\tTop5 test acc: 92.27424621582031\n",
            "Epoch 57\tTop1 Train accuracy 48.37890625\tTop1 Test accuracy: 47.99287796020508\tTop5 test acc: 92.28401184082031\n",
            "Epoch 58\tTop1 Train accuracy 48.43869400024414\tTop1 Test accuracy: 48.03194046020508\tTop5 test acc: 92.31330871582031\n",
            "Epoch 59\tTop1 Train accuracy 48.478553771972656\tTop1 Test accuracy: 48.03078842163086\tTop5 test acc: 92.294921875\n",
            "Epoch 60\tTop1 Train accuracy 48.5004768371582\tTop1 Test accuracy: 48.06985092163086\tTop5 test acc: 92.294921875\n",
            "Epoch 61\tTop1 Train accuracy 48.600128173828125\tTop1 Test accuracy: 48.11867904663086\tTop5 test acc: 92.3046875\n",
            "Epoch 62\tTop1 Train accuracy 48.628028869628906\tTop1 Test accuracy: 48.12844467163086\tTop5 test acc: 92.353515625\n",
            "Epoch 63\tTop1 Train accuracy 48.65194320678711\tTop1 Test accuracy: 48.18703842163086\tTop5 test acc: 92.3828125\n",
            "Epoch 64\tTop1 Train accuracy 48.679847717285156\tTop1 Test accuracy: 48.22610092163086\tTop5 test acc: 92.3828125\n",
            "Epoch 65\tTop1 Train accuracy 48.71611785888672\tTop1 Test accuracy: 48.29446029663086\tTop5 test acc: 92.373046875\n",
            "Epoch 66\tTop1 Train accuracy 48.76594161987305\tTop1 Test accuracy: 48.26516342163086\tTop5 test acc: 92.40234375\n",
            "Epoch 67\tTop1 Train accuracy 48.79583740234375\tTop1 Test accuracy: 48.28469467163086\tTop5 test acc: 92.40119934082031\n",
            "Epoch 68\tTop1 Train accuracy 48.84765625\tTop1 Test accuracy: 48.38235092163086\tTop5 test acc: 92.41096496582031\n",
            "Epoch 69\tTop1 Train accuracy 48.891502380371094\tTop1 Test accuracy: 48.44094467163086\tTop5 test acc: 92.42073059082031\n",
            "Epoch 70\tTop1 Train accuracy 48.92338943481445\tTop1 Test accuracy: 48.45071029663086\tTop5 test acc: 92.39143371582031\n",
            "Epoch 71\tTop1 Train accuracy 48.95527648925781\tTop1 Test accuracy: 48.49953842163086\tTop5 test acc: 92.40119934082031\n",
            "Epoch 72\tTop1 Train accuracy 48.983177185058594\tTop1 Test accuracy: 48.48000717163086\tTop5 test acc: 92.40119934082031\n",
            "Epoch 73\tTop1 Train accuracy 49.02104568481445\tTop1 Test accuracy: 48.51906967163086\tTop5 test acc: 92.43049621582031\n",
            "Epoch 74\tTop1 Train accuracy 49.048946380615234\tTop1 Test accuracy: 48.50930404663086\tTop5 test acc: 92.44026184082031\n",
            "Epoch 75\tTop1 Train accuracy 49.068878173828125\tTop1 Test accuracy: 48.57766342163086\tTop5 test acc: 92.43049621582031\n",
            "Epoch 76\tTop1 Train accuracy 49.08880615234375\tTop1 Test accuracy: 48.59719467163086\tTop5 test acc: 92.42073059082031\n",
            "Epoch 77\tTop1 Train accuracy 49.12467956542969\tTop1 Test accuracy: 48.60696029663086\tTop5 test acc: 92.421875\n",
            "Epoch 78\tTop1 Train accuracy 49.160552978515625\tTop1 Test accuracy: 48.65578842163086\tTop5 test acc: 92.431640625\n",
            "Epoch 79\tTop1 Train accuracy 49.194435119628906\tTop1 Test accuracy: 48.66555404663086\tTop5 test acc: 92.44140625\n",
            "Epoch 80\tTop1 Train accuracy 49.23429489135742\tTop1 Test accuracy: 48.71323776245117\tTop5 test acc: 92.421875\n",
            "Epoch 81\tTop1 Train accuracy 49.272159576416016\tTop1 Test accuracy: 48.73276901245117\tTop5 test acc: 92.4609375\n",
            "Epoch 82\tTop1 Train accuracy 49.296077728271484\tTop1 Test accuracy: 48.74253463745117\tTop5 test acc: 92.4609375\n",
            "Epoch 83\tTop1 Train accuracy 49.31201934814453\tTop1 Test accuracy: 48.82065963745117\tTop5 test acc: 92.44140625\n",
            "Epoch 84\tTop1 Train accuracy 49.3359375\tTop1 Test accuracy: 48.81089401245117\tTop5 test acc: 92.431640625\n",
            "Epoch 85\tTop1 Train accuracy 49.36782455444336\tTop1 Test accuracy: 48.82065963745117\tTop5 test acc: 92.431640625\n",
            "Epoch 86\tTop1 Train accuracy 49.393733978271484\tTop1 Test accuracy: 48.86948776245117\tTop5 test acc: 92.44140625\n",
            "Epoch 87\tTop1 Train accuracy 49.41565704345703\tTop1 Test accuracy: 48.88901901245117\tTop5 test acc: 92.44140625\n",
            "Epoch 88\tTop1 Train accuracy 49.42522048950195\tTop1 Test accuracy: 48.90855026245117\tTop5 test acc: 92.431640625\n",
            "Epoch 89\tTop1 Train accuracy 49.45112991333008\tTop1 Test accuracy: 48.92808151245117\tTop5 test acc: 92.431640625\n",
            "Epoch 90\tTop1 Train accuracy 49.46906661987305\tTop1 Test accuracy: 48.93784713745117\tTop5 test acc: 92.44140625\n",
            "Epoch 91\tTop1 Train accuracy 49.49497604370117\tTop1 Test accuracy: 48.93784713745117\tTop5 test acc: 92.4609375\n",
            "Epoch 92\tTop1 Train accuracy 49.52885818481445\tTop1 Test accuracy: 48.95737838745117\tTop5 test acc: 92.4609375\n",
            "Epoch 93\tTop1 Train accuracy 49.558753967285156\tTop1 Test accuracy: 48.93784713745117\tTop5 test acc: 92.470703125\n",
            "Epoch 94\tTop1 Train accuracy 49.58067321777344\tTop1 Test accuracy: 48.93784713745117\tTop5 test acc: 92.470703125\n",
            "Epoch 95\tTop1 Train accuracy 49.60658264160156\tTop1 Test accuracy: 48.95737838745117\tTop5 test acc: 92.490234375\n",
            "Epoch 96\tTop1 Train accuracy 49.64445114135742\tTop1 Test accuracy: 48.98667526245117\tTop5 test acc: 92.490234375\n",
            "Epoch 97\tTop1 Train accuracy 49.69028854370117\tTop1 Test accuracy: 48.98667526245117\tTop5 test acc: 92.5\n",
            "Epoch 98\tTop1 Train accuracy 49.720184326171875\tTop1 Test accuracy: 49.03550338745117\tTop5 test acc: 92.51953125\n",
            "Epoch 99\tTop1 Train accuracy 49.73014831542969\tTop1 Test accuracy: 49.04526901245117\tTop5 test acc: 92.51953125\n"
          ]
        }
      ],
      "source": [
        "checkpoint_filenames = ['checkpoint_0000.pth.tar']\n",
        "# checkpoint_filenames = ['checkpoint_0050.pth.tar', 'checkpoint_0100.pth.tar', 'checkpoint_0150.pth.tar' ]\n",
        "# checkpoint_filenames = ['checkpoint_0050.pth.tar', 'checkpoint_0100.pth.tar', 'checkpoint_0150.pth.tar', 'checkpoint_0200.pth.tar', 'checkpoint_0250.pth.tar', 'checkpoint_0300.pth.tar' ]\n",
        "\n",
        "for checkpoint_filename in checkpoint_filenames:\n",
        "\n",
        "  print(f\"\\n\\n\\n\\n\\n########################checkpoint {checkpoint_filename}##########################\\n\")\n",
        "\n",
        "  modified_resnet18 = torchvision.models.resnet18(pretrained=False, num_classes=10).to(device)\n",
        "  model = modify_resnet18_for_cifar10(modified_resnet18).to(device)\n",
        "\n",
        "\n",
        "  checkpoint = torch.load(f'{checkpoint_filename}', map_location=device)\n",
        "  # checkpoint = torch.load('runs/Apr23_11-52-29_Samme/checkpoint_0100.pth.tar', map_location=device)\n",
        "  state_dict = checkpoint['state_dict']\n",
        "\n",
        "  for k in list(state_dict.keys()):\n",
        "\n",
        "    if k.startswith('backbone.'):\n",
        "      if k.startswith('backbone') and not k.startswith('backbone.fc'):\n",
        "        # remove prefix\n",
        "        state_dict[k[len(\"backbone.\"):]] = state_dict[k]\n",
        "    del state_dict[k]\n",
        "\n",
        "  log = model.load_state_dict(state_dict, strict=False)\n",
        "  assert log.missing_keys == ['fc.weight', 'fc.bias']\n",
        "\n",
        "  train_loader, test_loader = get_cifar10_data_loaders(download=True)\n",
        "\n",
        "  # freeze all layers but the last fc\n",
        "  for name, param in model.named_parameters():\n",
        "      if name not in ['fc.weight', 'fc.bias']:\n",
        "          param.requires_grad = False\n",
        "\n",
        "  parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "  assert len(parameters) == 2  # fc.weight, fc.bias\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=0.0008)\n",
        "  criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "  epochs = 100\n",
        "  for epoch in range(epochs):\n",
        "    top1_train_accuracy = 0\n",
        "    for counter, (x_batch, y_batch) in enumerate(train_loader):\n",
        "      x_batch = x_batch.to(device)\n",
        "      y_batch = y_batch.to(device)\n",
        "\n",
        "      logits = model(x_batch)\n",
        "      loss = criterion(logits, y_batch)\n",
        "      top1 = accuracy(logits, y_batch, topk=(1,))\n",
        "      top1_train_accuracy += top1[0]\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    top1_train_accuracy /= (counter + 1)\n",
        "    top1_accuracy = 0\n",
        "    top5_accuracy = 0\n",
        "    for counter, (x_batch, y_batch) in enumerate(test_loader):\n",
        "      x_batch = x_batch.to(device)\n",
        "      y_batch = y_batch.to(device)\n",
        "\n",
        "      logits = model(x_batch)\n",
        "\n",
        "      top1, top5 = accuracy(logits, y_batch, topk=(1,5))\n",
        "      top1_accuracy += top1[0]\n",
        "      top5_accuracy += top5[0]\n",
        "\n",
        "    top1_accuracy /= (counter + 1)\n",
        "    top5_accuracy /= (counter + 1)\n",
        "    print(f\"Epoch {epoch}\\tTop1 Train accuracy {top1_train_accuracy.item()}\\tTop1 Test accuracy: {top1_accuracy.item()}\\tTop5 test acc: {top5_accuracy.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do Not Use RUN ALL to run following code. They are designed for \"random initialized\" weights to compare with SimCLR\n",
        "\n",
        "class StopExecution(Exception):\n",
        "    def _render_traceback_(self):\n",
        "        pass\n",
        "\n",
        "raise StopExecution(\"Intentionally stopping the notebook here.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "0K_901qMYia2",
        "outputId": "f37680d9-7589-4427-b13a-de7f6a6429b8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "StopExecution",
          "evalue": "Intentionally stopping the notebook here.",
          "traceback": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n\\n\\n\\n\\n######################## random initialized ##########################\\n\")\n",
        "\n",
        "modified_resnet18 = torchvision.models.resnet18(pretrained=False, num_classes=10).to(device)\n",
        "model = modify_resnet18_for_cifar10(modified_resnet18).to(device)\n",
        "\n",
        "# Initialize the weights\n",
        "for module in model.modules():\n",
        "    if isinstance(module, nn.Conv2d):\n",
        "        nn.init.normal_(module.weight, std=0.01)\n",
        "    elif isinstance(module, nn.BatchNorm2d):\n",
        "        nn.init.constant_(module.weight, 1)\n",
        "        nn.init.constant_(module.bias, 0)\n",
        "\n",
        "train_loader, test_loader = get_cifar10_data_loaders(download=True)\n",
        "\n",
        "# freeze all layers but the last fc\n",
        "for name, param in model.named_parameters():\n",
        "    if name not in ['fc.weight', 'fc.bias']:\n",
        "        param.requires_grad = False\n",
        "\n",
        "parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "assert len(parameters) == 2  # fc.weight, fc.bias\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=0.0008)\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "  top1_train_accuracy = 0\n",
        "  for counter, (x_batch, y_batch) in enumerate(train_loader):\n",
        "    x_batch = x_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    logits = model(x_batch)\n",
        "    loss = criterion(logits, y_batch)\n",
        "    top1 = accuracy(logits, y_batch, topk=(1,))\n",
        "    top1_train_accuracy += top1[0]\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  top1_train_accuracy /= (counter + 1)\n",
        "  top1_accuracy = 0\n",
        "  top5_accuracy = 0\n",
        "  for counter, (x_batch, y_batch) in enumerate(test_loader):\n",
        "    x_batch = x_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    logits = model(x_batch)\n",
        "\n",
        "    top1, top5 = accuracy(logits, y_batch, topk=(1,5))\n",
        "    top1_accuracy += top1[0]\n",
        "    top5_accuracy += top5[0]\n",
        "\n",
        "  top1_accuracy /= (counter + 1)\n",
        "  top5_accuracy /= (counter + 1)\n",
        "  print(f\"Epoch {epoch}\\tTop1 Train accuracy {top1_train_accuracy.item()}\\tTop1 Test accuracy: {top1_accuracy.item()}\\tTop5 test acc: {top5_accuracy.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HG1GKFeZgfj",
        "outputId": "bee7ccd4-4626-476e-82a8-840eaf7044e3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################## random initialized ##########################\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\tTop1 Train accuracy 17.312658309936523\tTop1 Test accuracy: 21.968061447143555\tTop5 test acc: 73.88844299316406\n",
            "Epoch 1\tTop1 Train accuracy 23.674665451049805\tTop1 Test accuracy: 25.62729835510254\tTop5 test acc: 77.49885559082031\n",
            "Epoch 2\tTop1 Train accuracy 26.316564559936523\tTop1 Test accuracy: 27.527572631835938\tTop5 test acc: 79.31468963623047\n",
            "Epoch 3\tTop1 Train accuracy 28.10746192932129\tTop1 Test accuracy: 28.795957565307617\tTop5 test acc: 80.49172973632812\n",
            "Epoch 4\tTop1 Train accuracy 29.380977630615234\tTop1 Test accuracy: 29.636947631835938\tTop5 test acc: 81.0862808227539\n",
            "Epoch 5\tTop1 Train accuracy 30.26227569580078\tTop1 Test accuracy: 30.388900756835938\tTop5 test acc: 81.591796875\n",
            "Epoch 6\tTop1 Train accuracy 31.033960342407227\tTop1 Test accuracy: 30.868566513061523\tTop5 test acc: 81.9215316772461\n",
            "Epoch 7\tTop1 Train accuracy 31.548946380615234\tTop1 Test accuracy: 31.403379440307617\tTop5 test acc: 82.32939147949219\n",
            "Epoch 8\tTop1 Train accuracy 31.979032516479492\tTop1 Test accuracy: 31.8709774017334\tTop5 test acc: 82.63212585449219\n",
            "Epoch 9\tTop1 Train accuracy 32.41748809814453\tTop1 Test accuracy: 32.20817947387695\tTop5 test acc: 82.83720397949219\n",
            "Epoch 10\tTop1 Train accuracy 32.708465576171875\tTop1 Test accuracy: 32.470703125\tTop5 test acc: 83.02159881591797\n",
            "Epoch 11\tTop1 Train accuracy 33.0213623046875\tTop1 Test accuracy: 32.8125\tTop5 test acc: 83.17784881591797\n",
            "Epoch 12\tTop1 Train accuracy 33.40401840209961\tTop1 Test accuracy: 33.07272720336914\tTop5 test acc: 83.38407897949219\n",
            "Epoch 13\tTop1 Train accuracy 33.712928771972656\tTop1 Test accuracy: 33.13361740112305\tTop5 test acc: 83.64659881591797\n",
            "Epoch 14\tTop1 Train accuracy 33.940128326416016\tTop1 Test accuracy: 33.33639907836914\tTop5 test acc: 83.71611022949219\n",
            "Epoch 15\tTop1 Train accuracy 34.17689514160156\tTop1 Test accuracy: 33.62821578979492\tTop5 test acc: 83.87120819091797\n",
            "Epoch 16\tTop1 Train accuracy 34.457908630371094\tTop1 Test accuracy: 33.773555755615234\tTop5 test acc: 83.95909881591797\n",
            "Epoch 17\tTop1 Train accuracy 34.609375\tTop1 Test accuracy: 33.899356842041016\tTop5 test acc: 84.01654815673828\n",
            "Epoch 18\tTop1 Train accuracy 34.796714782714844\tTop1 Test accuracy: 34.046993255615234\tTop5 test acc: 84.12281799316406\n",
            "Epoch 19\tTop1 Train accuracy 34.97847366333008\tTop1 Test accuracy: 34.173946380615234\tTop5 test acc: 84.14119720458984\n",
            "Epoch 20\tTop1 Train accuracy 35.15983581542969\tTop1 Test accuracy: 34.271602630615234\tTop5 test acc: 84.36580657958984\n",
            "Epoch 21\tTop1 Train accuracy 35.30931091308594\tTop1 Test accuracy: 34.330196380615234\tTop5 test acc: 84.42325592041016\n",
            "Epoch 22\tTop1 Train accuracy 35.42689514160156\tTop1 Test accuracy: 34.472084045410156\tTop5 test acc: 84.34513092041016\n",
            "Epoch 23\tTop1 Train accuracy 35.506614685058594\tTop1 Test accuracy: 34.655330657958984\tTop5 test acc: 84.41234588623047\n",
            "Epoch 24\tTop1 Train accuracy 35.58434295654297\tTop1 Test accuracy: 34.69554138183594\tTop5 test acc: 84.46977996826172\n",
            "Epoch 25\tTop1 Train accuracy 35.6879768371582\tTop1 Test accuracy: 34.81043243408203\tTop5 test acc: 84.47954559326172\n",
            "Epoch 26\tTop1 Train accuracy 35.80755615234375\tTop1 Test accuracy: 34.850643157958984\tTop5 test acc: 84.53813934326172\n",
            "Epoch 27\tTop1 Train accuracy 35.92514419555664\tTop1 Test accuracy: 34.94600296020508\tTop5 test acc: 84.62488555908203\n",
            "Epoch 28\tTop1 Train accuracy 36.056678771972656\tTop1 Test accuracy: 34.92761993408203\tTop5 test acc: 84.63465118408203\n",
            "Epoch 29\tTop1 Train accuracy 36.126434326171875\tTop1 Test accuracy: 34.94715118408203\tTop5 test acc: 84.75183868408203\n",
            "Epoch 30\tTop1 Train accuracy 36.17426681518555\tTop1 Test accuracy: 35.026424407958984\tTop5 test acc: 84.84949493408203\n",
            "Epoch 31\tTop1 Train accuracy 36.24800491333008\tTop1 Test accuracy: 34.997127532958984\tTop5 test acc: 84.95691680908203\n",
            "Epoch 32\tTop1 Train accuracy 36.34765625\tTop1 Test accuracy: 35.07640075683594\tTop5 test acc: 84.96668243408203\n",
            "Epoch 33\tTop1 Train accuracy 36.42139434814453\tTop1 Test accuracy: 35.12522888183594\tTop5 test acc: 85.01551055908203\n",
            "Epoch 34\tTop1 Train accuracy 36.48118591308594\tTop1 Test accuracy: 35.133846282958984\tTop5 test acc: 85.07410430908203\n",
            "Epoch 35\tTop1 Train accuracy 36.55492401123047\tTop1 Test accuracy: 35.21082305908203\tTop5 test acc: 85.16199493408203\n",
            "Epoch 36\tTop1 Train accuracy 36.596778869628906\tTop1 Test accuracy: 35.231502532958984\tTop5 test acc: 85.22058868408203\n",
            "Epoch 37\tTop1 Train accuracy 36.66294479370117\tTop1 Test accuracy: 35.251033782958984\tTop5 test acc: 85.25850677490234\n",
            "Epoch 38\tTop1 Train accuracy 36.76857376098633\tTop1 Test accuracy: 35.260799407958984\tTop5 test acc: 85.29871368408203\n",
            "Epoch 39\tTop1 Train accuracy 36.790496826171875\tTop1 Test accuracy: 35.27918243408203\tTop5 test acc: 85.25218963623047\n",
            "Epoch 40\tTop1 Train accuracy 36.860252380371094\tTop1 Test accuracy: 35.38545608520508\tTop5 test acc: 85.27172088623047\n",
            "Epoch 41\tTop1 Train accuracy 36.91007614135742\tTop1 Test accuracy: 35.48311233520508\tTop5 test acc: 85.27172088623047\n",
            "Epoch 42\tTop1 Train accuracy 36.94993591308594\tTop1 Test accuracy: 35.55147171020508\tTop5 test acc: 85.29125213623047\n",
            "Epoch 43\tTop1 Train accuracy 36.967872619628906\tTop1 Test accuracy: 35.61121368408203\tTop5 test acc: 85.34984588623047\n",
            "Epoch 44\tTop1 Train accuracy 36.99577331542969\tTop1 Test accuracy: 35.64051055908203\tTop5 test acc: 85.38774871826172\n",
            "Epoch 45\tTop1 Train accuracy 37.07350158691406\tTop1 Test accuracy: 35.57215118408203\tTop5 test acc: 85.41704559326172\n",
            "Epoch 46\tTop1 Train accuracy 37.109375\tTop1 Test accuracy: 35.55491638183594\tTop5 test acc: 85.41704559326172\n",
            "Epoch 47\tTop1 Train accuracy 37.12491989135742\tTop1 Test accuracy: 35.55491638183594\tTop5 test acc: 85.42681121826172\n",
            "Epoch 48\tTop1 Train accuracy 37.17673873901367\tTop1 Test accuracy: 35.58421325683594\tTop5 test acc: 85.40727996826172\n",
            "Epoch 49\tTop1 Train accuracy 37.21659851074219\tTop1 Test accuracy: 35.641658782958984\tTop5 test acc: 85.40727996826172\n",
            "Epoch 50\tTop1 Train accuracy 37.26243591308594\tTop1 Test accuracy: 35.66233825683594\tTop5 test acc: 85.41704559326172\n",
            "Epoch 51\tTop1 Train accuracy 37.26243591308594\tTop1 Test accuracy: 35.71116638183594\tTop5 test acc: 85.44634246826172\n",
            "Epoch 52\tTop1 Train accuracy 37.3182373046875\tTop1 Test accuracy: 35.71116638183594\tTop5 test acc: 85.42681121826172\n",
            "Epoch 53\tTop1 Train accuracy 37.33617401123047\tTop1 Test accuracy: 35.710018157958984\tTop5 test acc: 85.42681121826172\n",
            "Epoch 54\tTop1 Train accuracy 37.38600158691406\tTop1 Test accuracy: 35.739315032958984\tTop5 test acc: 85.46472930908203\n",
            "Epoch 55\tTop1 Train accuracy 37.43383026123047\tTop1 Test accuracy: 35.739315032958984\tTop5 test acc: 85.49402618408203\n",
            "Epoch 56\tTop1 Train accuracy 37.455753326416016\tTop1 Test accuracy: 35.739315032958984\tTop5 test acc: 85.54285430908203\n",
            "Epoch 57\tTop1 Train accuracy 37.50558090209961\tTop1 Test accuracy: 35.80652618408203\tTop5 test acc: 85.58191680908203\n",
            "Epoch 58\tTop1 Train accuracy 37.52949523925781\tTop1 Test accuracy: 35.85535430908203\tTop5 test acc: 85.60144805908203\n",
            "Epoch 59\tTop1 Train accuracy 37.559391021728516\tTop1 Test accuracy: 35.88465118408203\tTop5 test acc: 85.62097930908203\n",
            "Epoch 60\tTop1 Train accuracy 37.60762023925781\tTop1 Test accuracy: 35.89326858520508\tTop5 test acc: 85.62097930908203\n",
            "Epoch 61\tTop1 Train accuracy 37.63352966308594\tTop1 Test accuracy: 35.91279983520508\tTop5 test acc: 85.63074493408203\n",
            "Epoch 62\tTop1 Train accuracy 37.669403076171875\tTop1 Test accuracy: 35.96162796020508\tTop5 test acc: 85.65027618408203\n",
            "Epoch 63\tTop1 Train accuracy 37.67737579345703\tTop1 Test accuracy: 35.95186233520508\tTop5 test acc: 85.64913177490234\n",
            "Epoch 64\tTop1 Train accuracy 37.70726776123047\tTop1 Test accuracy: 35.98115921020508\tTop5 test acc: 85.67842864990234\n",
            "Epoch 65\tTop1 Train accuracy 37.72719955444336\tTop1 Test accuracy: 35.94209671020508\tTop5 test acc: 85.68819427490234\n",
            "Epoch 66\tTop1 Train accuracy 37.7630729675293\tTop1 Test accuracy: 35.96162796020508\tTop5 test acc: 85.67727661132812\n",
            "Epoch 67\tTop1 Train accuracy 37.79695510864258\tTop1 Test accuracy: 35.98977279663086\tTop5 test acc: 85.68704223632812\n",
            "Epoch 68\tTop1 Train accuracy 37.817283630371094\tTop1 Test accuracy: 35.98000717163086\tTop5 test acc: 85.65774536132812\n",
            "Epoch 69\tTop1 Train accuracy 37.85714340209961\tTop1 Test accuracy: 35.98000717163086\tTop5 test acc: 85.64913177490234\n",
            "Epoch 70\tTop1 Train accuracy 37.908958435058594\tTop1 Test accuracy: 36.00930404663086\tTop5 test acc: 85.63936614990234\n",
            "Epoch 71\tTop1 Train accuracy 37.922908782958984\tTop1 Test accuracy: 35.98000717163086\tTop5 test acc: 85.67727661132812\n",
            "Epoch 72\tTop1 Train accuracy 37.956790924072266\tTop1 Test accuracy: 36.00930404663086\tTop5 test acc: 85.66751098632812\n",
            "Epoch 73\tTop1 Train accuracy 37.98270034790039\tTop1 Test accuracy: 35.98977279663086\tTop5 test acc: 85.66751098632812\n",
            "Epoch 74\tTop1 Train accuracy 37.99067306518555\tTop1 Test accuracy: 36.01906967163086\tTop5 test acc: 85.67727661132812\n",
            "Epoch 75\tTop1 Train accuracy 38.01458740234375\tTop1 Test accuracy: 36.06789779663086\tTop5 test acc: 85.70657348632812\n",
            "Epoch 76\tTop1 Train accuracy 38.04248809814453\tTop1 Test accuracy: 35.98000717163086\tTop5 test acc: 85.72610473632812\n",
            "Epoch 77\tTop1 Train accuracy 38.06640625\tTop1 Test accuracy: 35.98977279663086\tTop5 test acc: 85.73587036132812\n",
            "Epoch 78\tTop1 Train accuracy 38.118221282958984\tTop1 Test accuracy: 35.94209671020508\tTop5 test acc: 85.6956558227539\n",
            "Epoch 79\tTop1 Train accuracy 38.12818908691406\tTop1 Test accuracy: 35.99092483520508\tTop5 test acc: 85.67727661132812\n",
            "Epoch 80\tTop1 Train accuracy 38.13616180419922\tTop1 Test accuracy: 36.00069046020508\tTop5 test acc: 85.6858901977539\n",
            "Epoch 81\tTop1 Train accuracy 38.17801284790039\tTop1 Test accuracy: 36.03975296020508\tTop5 test acc: 85.6663589477539\n",
            "Epoch 82\tTop1 Train accuracy 38.20989990234375\tTop1 Test accuracy: 36.07881546020508\tTop5 test acc: 85.6858901977539\n",
            "Epoch 83\tTop1 Train accuracy 38.22783660888672\tTop1 Test accuracy: 36.05928421020508\tTop5 test acc: 85.6663589477539\n",
            "Epoch 84\tTop1 Train accuracy 38.263710021972656\tTop1 Test accuracy: 36.03975296020508\tTop5 test acc: 85.6565933227539\n",
            "Epoch 85\tTop1 Train accuracy 38.30955123901367\tTop1 Test accuracy: 36.05928421020508\tTop5 test acc: 85.6565933227539\n",
            "Epoch 86\tTop1 Train accuracy 38.33784866333008\tTop1 Test accuracy: 36.09719467163086\tTop5 test acc: 85.6858901977539\n",
            "Epoch 87\tTop1 Train accuracy 38.365753173828125\tTop1 Test accuracy: 36.09719467163086\tTop5 test acc: 85.6858901977539\n",
            "Epoch 88\tTop1 Train accuracy 38.379703521728516\tTop1 Test accuracy: 36.10696029663086\tTop5 test acc: 85.6468276977539\n",
            "Epoch 89\tTop1 Train accuracy 38.3697395324707\tTop1 Test accuracy: 36.11672592163086\tTop5 test acc: 85.6468276977539\n",
            "Epoch 90\tTop1 Train accuracy 38.377708435058594\tTop1 Test accuracy: 36.12649154663086\tTop5 test acc: 85.6272964477539\n",
            "Epoch 91\tTop1 Train accuracy 38.40162658691406\tTop1 Test accuracy: 36.12764358520508\tTop5 test acc: 85.6370620727539\n",
            "Epoch 92\tTop1 Train accuracy 38.44148635864258\tTop1 Test accuracy: 36.13740921020508\tTop5 test acc: 85.6370620727539\n",
            "Epoch 93\tTop1 Train accuracy 38.4673957824707\tTop1 Test accuracy: 36.14717483520508\tTop5 test acc: 85.6077651977539\n",
            "Epoch 94\tTop1 Train accuracy 38.48533248901367\tTop1 Test accuracy: 36.12764358520508\tTop5 test acc: 85.56985473632812\n",
            "Epoch 95\tTop1 Train accuracy 38.49728775024414\tTop1 Test accuracy: 36.15694046020508\tTop5 test acc: 85.56008911132812\n",
            "Epoch 96\tTop1 Train accuracy 38.51123809814453\tTop1 Test accuracy: 36.18623733520508\tTop5 test acc: 85.54055786132812\n",
            "Epoch 97\tTop1 Train accuracy 38.50326919555664\tTop1 Test accuracy: 36.14717483520508\tTop5 test acc: 85.57962036132812\n",
            "Epoch 98\tTop1 Train accuracy 38.509246826171875\tTop1 Test accuracy: 36.11787796020508\tTop5 test acc: 85.56008911132812\n",
            "Epoch 99\tTop1 Train accuracy 38.53116989135742\tTop1 Test accuracy: 36.10811233520508\tTop5 test acc: 85.54055786132812\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}