# SimCLR-ResNet

Adapted SimCLR framework on modified ResNet, comparing with RotNet and exploring semi-supervised fine-tuning.

## Mainly Code Reference

- [SimCLR](https://github.com/sthalles/SimCLR)

- [RotNet](https://github.com/jiayueLiiu/unsupervisedLearning)

## Authors

- Yujie Huang

- Yi Li

- Haobo Yuan

## Abstract
Exploration and implementation of two self-supervised frameworks, SimCLR and RotNet, with ResNet-20 on CIFAR-10, underscoring the potency of self-supervised learning in scenarios where labeled data is scarce.

## Introduction
Discussion on the dependency on labeled datasets in machine learning and how self-supervised learning approaches like SimCLR are addressing this challenge.

## Related Works
Review of seminal frameworks in self-supervised learning, focusing on contrastive learning, and its implications for future research directions.

## Methodology
Detailed exposition of the methodology encompassing data augmentation strategies, implementation specifics of SimCLR with ResNet-20, and the contrastive loss function.

## Experiments
Outline of the experimental setup, description of CIFAR-10, implementation details of SimCLR, and semi-supervised learning performance metrics.

## Conclusion
Validation of the self-supervised learning approach, its advantages in semi-supervised settings, and its potential in enhancing model resilience and generalization.
